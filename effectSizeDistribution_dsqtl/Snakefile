import os
import pandas

include: "../Snakefile_config"
include: "Snakefile_prunePlink"

DIRECTORIES.update({
    'eqtlIndexDir' : "gregorRun/index_snpFiles",
    'gregorRun' : "gregorRun"
}) 

SCRIPTS = {
    'plot' : "scripts/plot.R",
    'pruningScript' : "scripts/pruneVariantsAndFilterMaf_1000gNCIPortal.py",
    'makeConfFile' : "scripts/gregor_makeConf.py",
    'proxyFromGREGOR' : "scripts/gregorOutputCompileLdSnps.py",
}

rule final:
    """
    Plot effect size for dsQTL lying in different annotations
    """
    input:
        effectSize = expand(os.path.join(DIRECTORIES['figures'], "fig.dsqtl.prune{prune_r2}.maf{maf}.ld{proxy_r2}.effectSizeInannotations.pdf"), prune_r2=config['prune_r2'], maf=config['maf'], proxy_r2=config['proxy_r2'])


rule makeBedfile:
    """ dsQTL table from Degner et al. Nature 2012 gives a full list of all DNase sensitivity quantitative trait loci (dsQTLs) identified using a 2 kb cis-candidate window around each 100bp test window.   Columns correspond to the chromosome start and end for the 100 bp window where DNase sensitivity was measured, the location of the most significantly associated SNP, the estimated effect size, standard error of this estimate, the t-statistic, and the p-value measuring the significance of the association.
    Make bed file from dsQTL dataframe
    """
    input:
        DATA['dsqtl']
    output:
        os.path.join(DIRECTORIES['intermediateFiles'], "dsQtlTable_hg18.bed"),
    shell:
        r"""
        zcat {input} | grep -v Start | awk '{{print $1,$4-1,$4,$5,$8}}' OFS='\t' > {output}
        """
        
rule liftover_to_hg19:
    """
    Liftover coordinates from hg18 to hg19
    """
    input:
        dsqtl = rules.makeBedfile.output,
        hg19_liftover = DATA['hg19_liftover']
    output:
        hg19file = os.path.join(DIRECTORIES['intermediateFiles'], "dsQtlTable_hg19.bed"),
        posfile = os.path.join(DIRECTORIES['intermediateFiles'], "dsQtlTable_hg19_pos.txt")
    shell:
        """
        liftOver {input.dsqtl} {input.hg19_liftover} {output.hg19file} {output.hg19file}.unmapped ;
        less {output.hg19file} | cut -f1,3 | sed -e 's:chr::g' | sort | uniq > {output.posfile}
        """
        
rule getRsID:
    """
    Get RsID from chrom and pos hg19 info using dbsnp vcf.; select SNV variant class, drop any duplicates
    Arrange the output in a format accepted by PLINK
    """
    input:
        dsqtl = rules.liftover_to_hg19.output.hg19file,
        dbsnp150 = DATA['dbsnp150']
    output:
        tempfile = temp(os.path.join(DIRECTORIES['intermediateFiles'], "dsqtl.temp.bed")),
        main = os.path.join(DIRECTORIES['intermediateFiles'], "dsqtl.withRsID.dat"),
        posfile = os.path.join(DIRECTORIES['intermediateFiles'], "dsqtl.RsID.txt")
    run:
        shell(r"""
        less {input.dsqtl} | sed -e 's:chr::g' | intersectBed -a - -b {input.dbsnp150} -wa -wb > {output.tempfile}
        """)
        d = pandas.read_csv(output.tempfile, sep='\t', header=None, names=['chrom','start','end','effect','P','chromvcf','pos','SNP','ref','alt','qual','filter','info'])
        # Separate SNPs where the input SNP position matches the RSPOS from the dbsnp info
        d = d[d.apply(lambda x: "RSPOS={val}".format(val=x.end) in x.info, axis=1)]

        # Get SNPs which have more than one rsID, retain the row containing SNV information
        dsub = d[d.duplicated(['chrom','start','end'], keep=False)]
        dsub = dsub[dsub['info'].str.contains("VC=SNV")].drop_duplicates(['chrom','end'])

        d.drop_duplicates(['chrom','start','end'], keep=False, inplace=True)
        dout = pandas.concat([d, dsub], ignore_index=True)
        dout[['chrom','start','end','effect','P','SNP']].to_csv(output.main, sep='\t', index=False)
        dout['SNP'].drop_duplicates().to_csv(output.posfile, index=False)


def getHeaderList(filename, extendlist):
    with open(filename, 'r') as f:
        l = f.readline().rstrip().split('\t')
        l.extend(extendlist)
        return l
    
rule getHeaderString:
    input:
        proxyfile = rules.mergeWithOriginal.output.main
    output:
        os.path.join(DIRECTORIES['intermediateFiles'], "headerstring.dsqtl.prune{prune_r2}.maf{maf}.ld{proxy_r2}.dat")
    run:
        var = '\t'.join(getHeaderList(input.proxyfile, ['cell','annotation']))
        with open(output[0], 'w') as the_file:
            the_file.write("{var}\n".format(var=var))

            
rule intersectAnnotations:
    """
    Intersect annotations with eQTL proxy SNPs
    """
    input:
        eqtlfile = rules.mergeWithOriginal.output.main,
        annotations = expand(DATA['annotations'], cell="GM12878", region = REGIONS),
        headerString = rules.getHeaderString.output
    output:
        main = os.path.join(DIRECTORIES['intermediateFiles'], "GM12878.dsqtl.prune{prune_r2}.maf{maf}.ld{proxy_r2}.annotations.dat"),
        tempout = temp(os.path.join(DIRECTORIES['intermediateFiles'], "GM12878.dsqtl.prune{prune_r2}.maf{maf}.ld{proxy_r2}.annotations.dat.temp"))
    shell:
        r"""
        for i in {input.annotations}; do b=`basename $i .annotations.bed | sed -e 's:\.:\t:g'`; grep -v chrom {input.eqtlfile} | intersectBed -a - -b $i | awk '{{print $0"\t""'"$b"'"}}' OFS='\t'; done | sort | uniq  > {output.tempout};
        cat {input.headerString} {output.tempout} > {output.main};
        """

rule plot:
    input:
        rules.intersectAnnotations.output.main
    output:
        os.path.join(DIRECTORIES['figures'], "fig.dsqtl.prune{prune_r2}.maf{maf}.ld{proxy_r2}.effectSizeInannotations.pdf")
    params:
        script = SCRIPTS['plot']
    shell:
        r""" 
        Rscript {params.script} {input} {output}
        """
                                                                    

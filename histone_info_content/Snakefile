import os
import pandas
import numpy
import pybedtools
import math
import sys

include: "../Snakefile_config"

CHROMHMM = config['SCRIPTS']['chromhmm']
CELLS = config['PARAMETERS']['cell']

CHROM = list(range(1, 23)) + ['X', 'Y']    
INTERMEDIATE_FILES = config['DIRECTORIES']['intermediateFiles']
FIGURES = config['DIRECTORIES']['figures'] 

SUBSET = {
    'fourcells' : ['GM12878','H1','HepG2','K562'],
}

stateDict = {
    'enhancer' : ['E3','E4','E5','E6'],
    'promoter' : ['E7','E8','E9','E10']
}

onsuccess:
    print("Workflow finished")

onerror:
    print("An error occurred")
                       

rule final:
    """ Learn a ChromHMM model using Islet histone, ATAC-seq and CAGE data """
    input:
        information = expand(os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "information_noNorm.{subset}_{stateType}.dat"),
                             subset = 'fourcells', stateType = ['enhancer','promoter'])
    
rule makeInputFilelist:
    input:
        binarized = expand(config['DATA']['binarized'], cell = SUBSET['allcells'], chrom = CHROM)
    output:
        inputfilelist = os.path.join(INTERMEDIATE_FILES, "segmentations", "inputfilelist"),
    run:
        with open(output.inputfilelist, 'w') as f:
            for b in input.binarized:
                f.write("{x}\n".format(x=os.path.basename(b)))
            
rule makeSegmentations:
    """Make ChromHMM Segmentations while also printing posterior probabilities """
    input:
        model = config['DATA']['state13_model'],
        binarized = expand(config['DATA']['binarized'], cell = SUBSET['allcells'], chrom = CHROM),
        inputfilelist = rules.makeInputFilelist.output.inputfilelist
    output:
        posteriors = expand(os.path.join(INTERMEDIATE_FILES, "segmentations/POSTERIOR", "{cell}_13_chr{chrom}_posterior.txt"),
                            cell = SUBSET['allcells'], chrom = CHROM),
        segments = temp(expand(os.path.join(INTERMEDIATE_FILES, "segmentations", "{cell}_13_segments.bed"),
                               cell = SUBSET['allcells'])),
    params:
        binarizedDir = "/lab/work/arushiv/chromatin/integrativeAnalysis_Chromhmm/bed_binarized/",
        outputDir = os.path.join(INTERMEDIATE_FILES, "segmentations")
    shell:
        r"""
        {CHROMHMM} MakeSegmentation -printposterior -f {input.inputfilelist} {input.model} {params.binarizedDir} {params.outputDir}  ; 
        """

rule make200bpTiles_byChrom:
    input:
        hg19_lengths = config['DATA']['hg19_lengths'],
    output:
        tile200bed = os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior/200bptiles", "chr{chrom}.200.bed")
    run:
        # get indices
        dchrom = pandas.read_csv(input.hg19_lengths, sep='\t', header=None, names=['chrom','length'])
        numlines = int(dchrom[dchrom['chrom'] == f"chr{wildcards.chrom}"].iloc[0]['length'] / 200)
        df = pandas.DataFrame({'start' : numpy.arange(0, 200*numlines, 200)})
        df.loc[:,'end'] = numpy.arange(200, 200*(numlines + 1), 200)
        df.loc[:,'chrom'] = f"chr{wildcards.chrom}"
        df.reset_index(inplace=True)
        df[['chrom','start','end','index']].to_csv(output.tile200bed, sep='\t', header=False, index=False)
        

rule getPosteriors:
    """Get avg posteriors for each feature in an annotation """
    input:
        posteriors = lambda wildcards: expand(os.path.join(INTERMEDIATE_FILES, "segmentations/POSTERIOR", "{cell}_13_chr{chrom}_posterior.txt"),
                                                        cell = SUBSET[wildcards.subset], chrom = wildcards.chrom),
        annotation = DATA['annotations'],
        tile200bed = rules.make200bpTiles_byChrom.output.tile200bed
    output:
        segmented_posteriors = os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "{cell}.{region}.chr{chrom}.{stateType}.{subset}.avgPosteriors.txt"),
        information = os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "{cell}.{region}.chr{chrom}.{stateType}.{subset}.information_noNorm.txt")
    params:
        states = lambda wildcards: ' '.join(stateDict[wildcards.stateType]),
        script = config['SCRIPTS']['calculate_avgPosterior'],
        replaceString = "_13_chr{chrom}_posterior.txt",
        cellName = "{cell}",
        annotName = "{region}",
    shell:
        """
        python {params.script} --inputfiles {input.posteriors} --annotationfile {input.annotation} --tilefile {input.tile200bed} --outputfile {output.segmented_posteriors} --states {params.states} \
        --cellName {params.cellName} --annotName {params.annotName} --replaceString {params.replaceString} --infoContent_file {output.information}
        """

rule calculate_ESI:
    input:
        posteriors = rules.getPosteriors.output.segmented_posteriors,
    output:
        esi = os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "{cell}.{region}.chr{chrom}.ESI.{stateType}.{subset}.txt")
    run:
        import sys
        sys.path.insert(0, '/home/arushiv/toolScripts')
        from esiScoreAfterMean import calculate_ESI
        
        def calc(filename):
            t = pandas.read_csv(filename, sep='\t')
            t.loc[:,'avg_post'] = t['avg_posterior']
            t.set_index(['chrom', 'start', 'end', 'infoContent', 'cell', 'annotation', 'avg_post'], inplace=True)
            t.rename(columns={'avg_posterior':wildcards.cell}, inplace=True)
            #print(t.head())
            out = calculate_ESI(t)
            out.reset_index(inplace=True)
            out.loc[:,'ESI'] = out[wildcards.cell]
            #print(out[['avg_post','GM12878']].head())
            return out

        try:
            out = calc(input.posteriors)
        except pandas.errors.EmptyDataError:
            out =  pandas.DataFrame()

        out.to_csv(output.esi, sep='\t', index=False, na_rep="NA")

        
rule concat_information:
    input:
        information = expand(os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "{cell}.{region}.chr{chrom}.{{stateType}}.{{subset}}.information_noNorm.txt"),
                            cell = CELLS, region = REGIONS , chrom = CHROM)
    output:
        information = os.path.join(INTERMEDIATE_FILES, "calculate_avg_posterior", "information_noNorm.{subset}_{stateType}.dat") 
    run:
        def read(filename):
            try:
                return pandas.read_csv(filename, sep='\t')
            except pandas.errors.EmptyDataError:
                return pandas.DataFrame()
            
        outdf = pandas.concat([read(filename) for filename in input.information])
        outdf.to_csv(output.information, sep='\t', index=False, na_rep='NA')
        
        


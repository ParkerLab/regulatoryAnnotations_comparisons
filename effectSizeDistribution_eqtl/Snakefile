import os
import pandas

include: "../Snakefile_config"
include: "Snakefile_parameters"
include: "Snakefile_prunePlink"

# include: "Snakefile_getProxies"
DIRECTORIES.update({
    'regression' : "regression",
    'eqtlIndexDir' : "gregorRun/index_snpFiles",
    'gregorRun' : "gregorRun"
}) 

SCRIPTS = {
    'effectVsMaf' : "scripts/plot_effectVsMaf.R",
    'pruningScript' : "scripts/pruneVariantsAndFilterMaf_1000gNCIPortal.py",
    'makeConfFile' : "scripts/gregor_makeConf.py",
    'proxyFromGREGOR' : "scripts/gregorOutputCompileLdSnps.py",
    'plot' : "scripts/plot.R",
    'regression' : "scripts/regress.py"
}

CHROM = list(range(1, 23))

rule final:
    """
    GTEx gene based FDR 10% eQTL set - 
    1. Prune by LD
    2. Filter by MAF
    3. Get r2>0.99 buddies
    4. Intersect with annotations and plot
    """
    input:
        expand(os.path.join(DIRECTORIES['figures'], "gtexV7.significantfdr{fdr}.effectVsMAF.pdf"), fdr = PARAMETERS['fdr']),
        expand(os.path.join(DIRECTORIES['intermediateFiles'], "pruned.proxies.significantfdr{fdr}.maf{maf}.dat"), fdr = PARAMETERS['fdr'], maf = PARAMETERS['maf']),

        # expand(os.path.join(DIRECTORIES['figures'], "fig.gtexV7.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.effectSizeInannotations.pdf"),
        #        fdr = PARAMETERS['fdr'], prune_r2 = PARAMETERS['prune_r2'], maf = PARAMETERS['maf'], gregor_r2 = PARAMETERS['gregor_r2']),
        # expand(os.path.join(DIRECTORIES['regression'], "regress_SEvsTE.allInfo.gtex.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.ATACPeaksChromStates.dat"),
        #        fdr = PARAMETERS['fdr'], prune_r2 = PARAMETERS['prune_r2'], maf = PARAMETERS['maf'], gregor_r2 = PARAMETERS['gregor_r2'])
        
rule formatEqtlFile:
    """Select by FDR threshold, retain 1 assocaiation per SNP """
    input:
        eqtlfile = DATA['gtex_eqtl']
    output:
        full = os.path.join(DIRECTORIES['intermediateFiles'], "gtexV7.significantfdr{fdr}.dat"),
    run:
        d = pandas.read_csv(input[0], sep='\t', usecols=['gene_id', 'gene_name', 'tss_distance', 'chr', 'pos', 'ref', 'alt', 'rs_id_dbSNP147_GRCh37p13', 'maf', 'pval_nominal', 'slope', 'qval'])
        d.rename(columns={'rs_id_dbSNP147_GRCh37p13' : 'SNP', 'chr' : 'chrom'}, inplace=True)
        d = d[d['qval'] <= float(wildcards.fdr)]
        d.sort_values(['qval'], inplace=True)
        d.drop_duplicates(['SNP'], inplace=True) # if SNP associated with 2 or more genes, keep the stronger association
        d.to_csv(output.full, sep='\t', index=False)

rule plotEffectVsMAF:
    input:
        rules.formatEqtlFile.output
    output:
        os.path.join(DIRECTORIES['figures'], "gtexV7.significantfdr{fdr}.effectVsMAF.pdf")
    params:
        script = SCRIPTS['effectVsMaf']
    shell:
        r"""
        Rscript {params.script} {input} {output}
        """

rule setup_eqtl_for_pruning:
    """
    Filter by MAF and setup file header names for plink clump input
    Pruning using Snakefile_prunePlink
    Then use Snakefile_getProxies to fetch proxies"""
    input:
        rules.formatEqtlFile.output.full
    output:
        full = os.path.join(DIRECTORIES['intermediateFiles'], "forPruning.gtexV7.significantfdr{fdr}.maf{maf}.dat"),
        snplist = os.path.join(DIRECTORIES['intermediateFiles'], "snplist_to_subset.significantfdr{fdr}.maf{maf}.dat"),
    run:
        d = pandas.read_csv(input[0], sep='\t')
        d.rename(columns={'qval' : 'P'}, inplace=True) # plink requires p val column to select one SNP per clump
        d = d[d['maf'] >= float(wildcards.maf)]
        d.to_csv(output.full, sep='\t', index=False)
        d[['SNP']].to_csv(output.snplist, header=False, index=False)

rule getProxies:
    
# rule organize_pruned_results:
#     """
#     Organize 
#     """

                                                                                                           
# rule organizeEqtlDF:
#     """
#     Merge proxies with pruned eQTL lead SNPs
#     remove unwanted columns
#     """
#     input:
#         proxyfile = rules.getProxies.output,
#         eqtlfile = rules.pruneUsingNCIPortal.output
#     output:
#         os.path.join(DIRECTORIES['intermediateFiles'], "gtexV7.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.dat")
#     run:
#         eqtlfile = pandas.read_csv(input.eqtlfile[0], sep='\t')
#         eqtlfile.loc[:,'chrom'] = eqtlfile['chrom'].map(lambda x: "chr{chrom}".format(chrom=x))
#         eqtlfile.rename(columns={'pos' : 'indexPos'}, inplace=True)
        
#         proxyfile = pandas.read_csv(input.proxyfile[0], sep='\t', header=None, names=['chrom','proxyStart','proxyEnd','indexPos'])
#         outdf = pandas.merge(proxyfile, eqtlfile, how="right", on=['chrom','indexPos'])
#         outdf.proxyEnd.fillna(outdf.indexPos, inplace=True)
#         outdf.proxyStart.fillna(outdf.indexPos - 1, inplace=True)
#         outdf[['proxyStart','proxyEnd']] = outdf[['proxyStart','proxyEnd']].astype(int)
#         d1 = outdf.groupby(['chrom','indexPos','gene_name']).size().reset_index(name='totalnumLD')
#         ndf = pandas.merge(outdf, d1, how="left", on=['chrom','indexPos','gene_name'])
#         ndf.to_csv(output[0], sep='\t', index=False, na_rep="NA")

# def getHeaderList(filename, extendlist):
#     with open(filename, 'r') as f:
#         l = f.readline().rstrip().split('\t')
#         l.extend(extendlist)
#         return l

# rule getHeaderString:
#     input:
#         proxyfile = rules.organizeEqtlDF.output
#     output:
#         os.path.join(DIRECTORIES['intermediateFiles'], "headerstring.gtex.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.dat")
#     run:
#         var = '\t'.join(getHeaderList(input.proxyfile[0], ['cell','annotation']))
#         with open(output[0], 'w') as the_file:
#             the_file.write("{var}\n".format(var=var))
            
# rule intersectAnnotations:
#     """
#     Intersect annotations with eQTL proxy SNPs
#     """
#     input:
#         eqtlfile = rules.organizeEqtlDF.output,
#         annotations = expand(DATA['annotations'], cell="GM12878", region = REGIONS),
#         headerString = rules.getHeaderString.output
#     output:
#         main = os.path.join(DIRECTORIES['intermediateFiles'], "GM12878.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.annotations.dat"),
#         tempout = temp(os.path.join(DIRECTORIES['intermediateFiles'], "GM12878.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.annotations.dat.temp"))
#     shell:
#         r"""
#         for i in {input.annotations}; do b=`basename $i .annotations.bed | sed -e 's:\.:\t:g'`; grep -v chrom {input.eqtlfile} | intersectBed -a - -b $i | awk '{{print $0"\t""'"$b"'"}}' OFS='\t'; done | sort | uniq  > {output.tempout};
# g        cat {input.headerString} {output.tempout} > {output.main};
#         """
    
# rule plot:
#     input:
#         rules.intersectAnnotations.output.main
#     output:
#         os.path.join(DIRECTORIES['figures'], "fig.gtexV7.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.effectSizeInannotations.pdf")
#     params:
#         script = SCRIPTS['plot']
#     shell:
#         r""" 
#         Rscript {params.script} {input} {output}
#         """ 
        
# rule regress:
#     input:
#         rules.intersectAnnotations.output.main
#     output:
#         os.path.join(DIRECTORIES['regression'], "regress_SEvsTE.allInfo.gtex.fdr{fdr}.prune{prune_r2}.maf{maf}.ld{gregor_r2}.ATACPeaksChromStates.dat"),
#     params:
#         script = SCRIPTS['regression']
#     shell:
#         r"""
#         python {params.script} --inputfile {input} --typereg intpeaks > {output};
#         """
                                                                    
# rule setup_powerCalc:
#     input:
#         expand(rules.intersectAnnotations.output.main, fdr=0.1, prune_r2=0.8, maf=0.2, gregor_r2=0.99)
#     output:
#         os.path.join(DIRECTORIES['intermediateFiles'], "summaryByAnnotation.txt")
#     run:
#         d = pandas.read_csv(input[0], sep="\t")
#         d.drop_duplicates(['chrom','snp','annotation'], inplace=True)
#         d.loc[:,'absoluteEffect'] = abs(d['slope'])
#         nd = d.groupby('annotation')['absoluteBeta'].describe().reset_index().rename(columns={'25%':'p_25','50%':'p_50','75%':'p_75'})
#         nd.to_csv(output[0], sep='\t', index=False)
        
# rule plot_power:
#     input:
#         rules.setup_powerCalc.output
#     output:
#         os.path.join(DIRECTORIES['figures'], "GM12878.powerCalc.pdf")
#     params:
#         script = SCRIPTS['powerCalc']
#     shell:
#         r"""
#         Rscript {params.script} {input} {output}
#         """
                                                                                                                                                        
